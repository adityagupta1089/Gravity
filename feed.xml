<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aditya Gupta</title>
    <description></description>
    <link>https://adityagupta1089.github.io/</link>
    <atom:link href="https://adityagupta1089.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 26 Oct 2019 20:34:50 +0000</pubDate>
    <lastBuildDate>Sat, 26 Oct 2019 20:34:50 +0000</lastBuildDate>
    <generator>Jekyll v3.8.6</generator>
    
      <item>
        <title>Strassen Matrix Multiplication</title>
        <description>&lt;p&gt;The product of two $n\times n$ matrices $X$ and $Y$ which takes $O(n^3)$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X=\begin{bmatrix}A&amp;B\\C&amp;D\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
Y=\begin{bmatrix}E&amp;F\\G&amp;H\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;is 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
XY=\begin{bmatrix}A&amp;B\\C&amp;D\end{bmatrix}\begin{bmatrix}E&amp;F\\G&amp;H\end{bmatrix}=\begin{bmatrix}AE+BG&amp;AF+BH\\CE+DG&amp;CF+DH\end{bmatrix} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;here $T(n)=8T(n/2)+O(n^2)\implies O(n^3)$&lt;/p&gt;

&lt;p&gt;Strassen gave:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
XY=\begin{bmatrix}P_5+P_4-P_2+P_6&amp;P_1+P_2\\P_3+P_4&amp;P_1+P_5-P_3-P_7\end{bmatrix}
\ %]]&gt;&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
P_1&amp;=A(F-H)&amp;P_5&amp;=(A+D)(E+H)\\
P_2&amp;=(A+B)H&amp;P_6&amp;=(B-D)(G+H)\\
P_3&amp;=(C+D)E&amp;P_7&amp;=(A-C)(E+F)\\
P_4&amp;=D(G-E)\\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;The new running time is $T(n)=7T(n/2)+O(n^2)$ which by the master theorem works out to be $O(n^{\log_27})\approx O(n^{2.81})$&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Oct 2019 18:46:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/algorithms/matrix-multiplication.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/algorithms/matrix-multiplication.html</guid>
        
        
        <category>Notes</category>
        
        <category>Algorithms</category>
        
      </item>
    
      <item>
        <title>Mergesort, Quicksort and Quickselect</title>
        <description>&lt;h1 id=&quot;mergesort&quot;&gt;Mergesort&lt;/h1&gt;

&lt;p&gt;Split the list into 2 halves, recursively sort each half and then merge the two sorted sublists. For merging $x[1..k]$ and $y[1..l]$ into $z[1..k+l]$. The first element of $z$ is smaller of $x[1]$ and $y[1]$ and rest can be constrcuted recrusively.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\text{mergesort}(a[1..n]) =&amp;\text{merge}(\text{mergesort}(a[1..\lfloor n/2\rfloor]),\\&amp;\quad\text{mergesort}(a[\lfloor n/2\rfloor+1...n]))\\
\text{merge}(x[1..k],y[1..l])=&amp;\begin{cases}x[1]\circ\text{merge}(x[2..k],y[1..l])&amp;x[1]\le y[1]\\y[1]\circ\text{merge}(x[1..k],y[2..l])&amp;\text{otherwise}\end{cases}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Time Complexity $T(n)=2T(n/2)+O(n)\implies O(n\log n)$&lt;/p&gt;

&lt;h1 id=&quot;quicksort--quickselect&quot;&gt;Quicksort &amp;amp; Quickselect&lt;/h1&gt;

&lt;p&gt;Select a pivot $v$ (pick randomly). Split the array into three categories: elements smaller than $v$, those equal to $v$ and those greater than $v$. Call these $S_L$, $S_v$, and $S_R$ respectively. Recursively sort the array.&lt;/p&gt;

&lt;p&gt;Time complexity: $O(n^2)$ worst case. $O(n\log n)$ best and average case.&lt;/p&gt;

&lt;p&gt;For selecting the $k^{\rm th}$ element:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\text{selection}=
\begin{cases}
\text{selection(S_L, k)}&amp;k\le |S_L|\\
v &amp;|S_L|&lt;k\le|S_L|+|S_v|\\
\text{selection}(S_R, k-|S_L|-|S_v|)&amp;k&gt;|S_L|+|S_v|
\end{cases} %]]&gt;&lt;/script&gt;
Time complexity: $T(n)=T(n/2)+O(n)\implies O(n)$&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Oct 2019 18:35:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/algorithms/mergesort-quicksort-quickselect.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/algorithms/mergesort-quicksort-quickselect.html</guid>
        
        
        <category>Notes</category>
        
        <category>Algorithms</category>
        
      </item>
    
      <item>
        <title>Master's Theorem</title>
        <description>&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: $T(n)=aT(\lceil n/b\rceil)+O(n^d)$ for some constants $a&amp;gt;0,b&amp;gt;1,d\ge 0$ then
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
T(n)=\begin{cases}
O(n^d)&amp;d&gt;\log_b a\\
O(n^d\log n)&amp;d=\log_ba\\
O(n^{\log_ba})&amp;d&lt;\log_ba
\end{cases} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: &lt;img src=&quot;https://adityagupta1089.github.io/images/mastertheorem.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each problem of size $n$ is divided into $a$ subproblems of size $n/b$. Each level has problem of size $n/b^k$ and work done is:
&lt;script type=&quot;math/tex&quot;&gt;a^k\times O\left(\frac nb^k\right)^d=O(n^d)\times \left(\frac ab^d\right)^k&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;As $k$ goes from $0$ (root) to $\log_bn$ (the leaves), these form a geometric series with ratio $r=a/b^d$&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$r&amp;lt;1$: Decreasing series, sum is first term $O(n^d)$&lt;/li&gt;
  &lt;li&gt;$r&amp;gt;1$: Increasing series, sum is last term $O(n^{\log_ba})$&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n^d\left(\frac a{b^d}\right)^{\log_bn}=n^d\left(\frac{a^{\log_bn}}{(b^{\log_bn})^d}\right)=a^{\log_bn}=a^{(\log_an)(\log_ba)}=n^{\log_ba}&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;$r=1$: All $O(\log n)$ terms are equal to $O(n^d)$&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 26 Oct 2019 17:52:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/algorithms/master-s-theorem.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/algorithms/master-s-theorem.html</guid>
        
        
        <category>Notes</category>
        
        <category>Algorithms</category>
        
      </item>
    
      <item>
        <title>Integer Multiplication</title>
        <description>&lt;p&gt;To multiply $x$ and $y$, split them into left and right halves which are $n/2$ bits long.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
x&amp;=2^{n/2}x_L+x_R\\
y&amp;=2^{n/2}y_L+y_R\\
xy&amp;=(2^{n/2}x_L+x_R)(2^{n/2}y_L+y_R)\\
&amp;=2^nx_Ly_L+2^{n/2}(x_Ly_R+x_Ry_L)+x_Ry_R\\
x_Ly_R+x_Ry_R&amp;=(x_L+x_R)(y_L+y_R)-x_Ly_L-x_Ry_R
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Additional and multiplication by power of 2 takes linear time. We only need to calculate $x_Ly_L$, $x_Ry_R$ and $(x_L+x_R)(y_L+y_R)$ which we can calculate recursively.&lt;/p&gt;

&lt;p&gt;$T(n)=3T(n/2)+O(n)\implies T(n)=O(n^{\log_23})=O(n^{1.59})$&lt;/p&gt;
</description>
        <pubDate>Thu, 24 Oct 2019 15:02:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/algorithms/integer-multiplication.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/algorithms/integer-multiplication.html</guid>
        
        
        <category>Notes</category>
        
        <category>Algorithms</category>
        
      </item>
    
      <item>
        <title>Heaps - Binary, Binomial, Fibonacci</title>
        <description>&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Procedure&lt;/th&gt;
      &lt;th&gt;Binary Heap&lt;/th&gt;
      &lt;th&gt;Binomial Heap (worst case)&lt;/th&gt;
      &lt;th&gt;Fibonacci Heap (amortized)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Make Heap&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Insert&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$O(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Minimum&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
      &lt;td&gt;$O(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Extract Min&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Union&lt;/td&gt;
      &lt;td&gt;$\Theta(n)$&lt;/td&gt;
      &lt;td&gt;$O(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Decrease Key&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(1)$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Delete&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
      &lt;td&gt;$\Theta(\lg n)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;binary-heap&quot;&gt;Binary Heap&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/heap1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A binary heap is an array object which we can view as a nearly complete binary tree with pointers as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Parent: $\lfloor i/2\rfloor$&lt;/li&gt;
  &lt;li&gt;Left child: $2i$&lt;/li&gt;
  &lt;li&gt;Right child: $2i+1$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These satisfy the &lt;strong&gt;heap property,&lt;/strong&gt; i.e. for max-heap $A[{\rm Parent}(i)]\ge A[i]$ or vice versa for min-heap. A heap of height $h$ can have nodes from $2^h$(1 node at last level) to $2^{h+1}-1$(full tree). So $h\le \lg n \le h+1$ so $h=\lfloor \lg n\rfloor$.&lt;/p&gt;

&lt;h2 id=&quot;heapify-oholg-n&quot;&gt;Heapify $O(h)=O(\lg n)$&lt;/h2&gt;

&lt;p&gt;If binary tree at ${\rm Left}(i)$ and ${\rm Right}(i)$ satisfy the heap property but $A[i]$ does not then we need to perform heapify operation. In max-heap we exchange $A[i]$ with the largest of ${\rm Right}(i)$ and ${\rm Left}(i)$ and recursively perform heapify operation at the exchanged node (the new parent).&lt;/p&gt;

&lt;h2 id=&quot;building-on&quot;&gt;Building $O(n)$&lt;/h2&gt;

&lt;p&gt;Elements from $\lfloor n/2\rfloor+1$ to $n$ are all leaves of the tree so each is a 1-element heap. We run heapify on rest of the elements in order from $\lfloor n/2\rfloor$ to $1$. Total time taken for height $i$ is $2^i\cdot O(h-i)$. Sum over all levels is 
&lt;script type=&quot;math/tex&quot;&gt;O(\sum_{i=0}^{\lg n} 2^{h-i}.i) =O\left(\sum _{i=0}^{\lg n}2^h . \frac i{2^i}\right)=O\left(n\cdot\sum_{i=0}^{\lg n}\frac i{2^i}\right)=O(n)&lt;/script&gt;
Where $\sum_{x=0}^\infty x/2^x=x/(1-x)^2$ and we put $x=1/2$ to get $\sum i/2^i\le 2$.&lt;/p&gt;

&lt;h2 id=&quot;extract-min-olg-n&quot;&gt;Extract Min $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Replace min value with last element and perform heapify after removing the min element.&lt;/p&gt;

&lt;h1 id=&quot;binomial-heap&quot;&gt;Binomial Heap&lt;/h1&gt;

&lt;p&gt;A binomial tree $B_k$ is defined recursively consisting of two $B_{k-1}$ linked together.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/heap2.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A tree $B_k$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Contains $2^k$ nodes&lt;/li&gt;
  &lt;li&gt;has height $k$&lt;/li&gt;
  &lt;li&gt;there are $k \choose i$ nodes at depth $i$ (which gives it the name &lt;strong&gt;binomial heap&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;root has degree $k$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A binomial heap $H$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each binomial tree is heap ordered.&lt;/li&gt;
  &lt;li&gt;there is atmost 1 tree whose root has a given degree.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So a binomial heap $H$ has atmost $\lfloor\lg n\rfloor+1$ binomial trees (from binary representation)&lt;/p&gt;

&lt;h2 id=&quot;finding-min-olg-n&quot;&gt;Finding Min $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;See the roots of all $O(\lg n)$ trees.&lt;/p&gt;

&lt;h2 id=&quot;uniting-two-binomial-heaps-olg-n&quot;&gt;Uniting two binomial heaps $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;For merging two binomial trees $B_{k-1}$ with roots $y$ and $z$ we would make $z$ parent of $y$ and make the child of $z$ sibling of $y$. This takes $O(1)$ time.&lt;/p&gt;

&lt;p&gt;For merging two heaps we would do the same as binary addition. This would take $O(\lg n)$ time as there are atmax $\lg n$ trees.&lt;/p&gt;

&lt;h2 id=&quot;inserting-a-node-olg-n&quot;&gt;Inserting a node $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Create $B_0$ with the node and perform heap union.&lt;/p&gt;

&lt;h2 id=&quot;extracting-min-olg-n&quot;&gt;Extracting Min $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Merge the children of the tree with minimunm key with the rest of the trees.&lt;/p&gt;

&lt;h2 id=&quot;decreasing-a-key-olg-n&quot;&gt;Decreasing a key $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Change key value and perform heapify operation.&lt;/p&gt;

&lt;h2 id=&quot;deleting-a-key-olg-n&quot;&gt;Deleting a key $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Decrease key to $-\infty$ and extract min.&lt;/p&gt;

&lt;h1 id=&quot;fibonacci-heap&quot;&gt;Fibonacci Heap&lt;/h1&gt;

&lt;p&gt;A Fibonacci heap is a collection of trees that are heap-ordered connected in a circular, doubly linked list. Each node may also be marked. We also store the minimum of the heap using a separate pointer.&lt;/p&gt;

&lt;p&gt;Suppose&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;At some time, $x$ was a root.&lt;/li&gt;
  &lt;li&gt;then $x$ was linked to (made child of) another node&lt;/li&gt;
  &lt;li&gt;then two children of $x$ were removed by cut operation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As soon as second child has been lost we remove $x$ from it’s parents making it a new root. $x.{\rm mark}$ is true if steps $1$ and $2$ have occured and one child of $x$ has been cut.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Maximum degree of a node is $D(n)\le \lfloor\log_{\phi}n\rfloor$ where $\phi$ is the golden ration $\phi=(1+\sqrt 5)/2$. Hence $D(n)\le O(\lg n)$&lt;/p&gt;

&lt;h2 id=&quot;potential&quot;&gt;Potential&lt;/h2&gt;

&lt;p&gt;$t(H)$ represents the number of trees in heap $H$ and $m(H)$ represents the number of marked nodes in $H$. We define the potential of $H$ as $\phi(H)=t(H)+2m(H)$&lt;/p&gt;

&lt;h2 id=&quot;create-a-new-heap-o1&quot;&gt;Create a new heap $O(1)$&lt;/h2&gt;

&lt;p&gt;Just allocate empty heap $H$ with $0$ trees and &lt;code class=&quot;highlighter-rouge&quot;&gt;NULL&lt;/code&gt; min pointer $\phi(H)=0$&lt;/p&gt;

&lt;h2 id=&quot;insert-a-node-o1&quot;&gt;Insert a node $O(1)$&lt;/h2&gt;

&lt;p&gt;Just insert the node in the root list and update min-pointer if necessary. $\Delta\phi(H)=1$&lt;/p&gt;

&lt;h2 id=&quot;finding-the-min-o1&quot;&gt;Finding the min $O(1)$&lt;/h2&gt;

&lt;p&gt;Return the value pointed by min pointer. $\Delta \phi(H)=0$&lt;/p&gt;

&lt;h2 id=&quot;uniting-two-fibonacci-heaps-o1&quot;&gt;Uniting two fibonacci heaps $O(1)$&lt;/h2&gt;

&lt;p&gt;Concatenate two root lists and update min-pointer if necessary. 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}\Delta\phi(H)&amp;=\phi(H)-\phi(H_1)-\phi(H_2)\\&amp;=(t(H)+2m(H))-((t(H_1)+2m(H_1))+(t(H_2)+2m(H_2)))
\\&amp;=0\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;since $t(H)=t(H_1)+t(H_2)$ and $m(H)=m(H_1)+m(H_2)$&lt;/p&gt;

&lt;h2 id=&quot;extracting-the-min-node-olg-n&quot;&gt;Extracting the min node $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Add the children of tree whose root is pointer by min-pointer to the root list of $H$ and then remove it from the root list. Also update min pointer. This takes $O(D(n))$. Then consolidate the root list by linking roots of equal degrees until atmost one root remains of each degree. To link $y$ and $x$ remove $y$ from root list of $H$ and make $y$ child of $x$ and unmark $y$ is previously marked (step 2).&lt;/p&gt;

&lt;p&gt;The above operation will increate elements in root list to at most $D(n)+t(H)-1$, original $t(H)$ minus $1$ extracted node, new $D(n)$ children of extracted node. The total time taken for combining roots is therefore atmost $O(D(n)+t(H))$.&lt;/p&gt;

&lt;p&gt;The potential before is $t(H)+2m(H)$ and afterwards at most $(D(n)+1)+2m(H)$. Thus amortized cost is
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;O(D(n)+t(H))+((D(n)+1)+2m(H))-(t(H)+2m(H))\\
&amp;=O(D(n))+O(t(H))-t(H))\\
&amp;=O(D(n))
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;decreasing-a-key-o1&quot;&gt;Decreasing a key $O(1)$&lt;/h2&gt;

&lt;p&gt;Cut the link between the node $x$ with the key and it’s parent $y$, making $x$ the root (also unmark it if marked, step 1). This is a cut operation.  Then perform a cascading cut where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If $y$ is unmarked then mark it (since it has lost it’s first child)&lt;/li&gt;
  &lt;li&gt;Else perform cut operation at $y$ and perform cascading cut at $y$’s parent.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This goes on until a unmarked node or root is found. Finally we update the min-pointer. Total time taken is $O(1)$ for decreasing key, $O(c)$ for cascading cuts consisting of $c$ total cuts.&lt;/p&gt;

&lt;p&gt;For change in potential:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cutting $x$ from $y$ creates a new tree rooted at $x$ and clears $x$’s mark bit.&lt;/li&gt;
  &lt;li&gt;Each call of the cascading cut except for the last one cuts a marked node and clears the mark bit. Finally fibonacci heap contains $t(H)+c$ trees ($t(H)$ original, $c-1$ from cascading cuts and $1$ from $x$) and at most $m(H)-c+2$ marked nodes ($m(H)$ original, $c-1$ unmarked from cascading cuts except last one which marked $1$ node).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$((t(H)+c)+2(m(H)-c+2))-(t(H)+2m(H))=4-c$&lt;/p&gt;

&lt;p&gt;Thus total amortized time taken is $O(c)+4-c=O(1)$&lt;/p&gt;

&lt;p&gt;1 unit of potential pays for (i) cut and clearing the mark bit. (ii) decrease in potential due to node $y$ becoming a root.&lt;/p&gt;

&lt;h2 id=&quot;deleting-a-key-olg-n-1&quot;&gt;Deleting a key $O(\lg n)$&lt;/h2&gt;

&lt;p&gt;Decrease key to $-\infty$ and extract min.&lt;/p&gt;

</description>
        <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/data%20structures/heaps.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/data%20structures/heaps.html</guid>
        
        
        <category>Notes</category>
        
        <category>Data Structures</category>
        
      </item>
    
      <item>
        <title>Range Trees</title>
        <description>&lt;h1 id=&quot;motivation&quot;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;Given a set of $n$ points $P$ on a real line and a query interval $[x:x’]$ find all the points inside the interval.&lt;/p&gt;

&lt;p&gt;Construct a binary search tree from $P$ and perform the following query:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/rangetree1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure: Example of searching in range tree&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Search for $x$ and $x’$ until we get to $v_{\rm split}$ where the search path splits.&lt;/li&gt;
  &lt;li&gt;From the left child of $v_{\rm split}$ we continue search with $x$ and at every node $v$ we where search path goes left we all points in right subtree of $v$.&lt;/li&gt;
  &lt;li&gt;Symmetrically we go right from $v_{\rm split}$ searching for $x’$ and taking left subtrees of $v$ respectively.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;definition&quot;&gt;Definition&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Canonical Subset of node&lt;/strong&gt; $v$ (i.e. $P(v)$): subset of points stored in the leaves of the subtree at $v$.&lt;/p&gt;

&lt;h1 id=&quot;2-d-range-trees&quot;&gt;2-D Range Trees&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;The main tree is a balanced binary search tree built $T$ built on the x-coordinates of $P$.&lt;/li&gt;
  &lt;li&gt;For any internal node / leaf node $v$ in $T$, the canonical subset $P(v)$ is stored in a balanced binary search tree $T_1(v)$ on the y-coordinates of the points. The node $v$ contains a pointer to the root of $T_1(v)$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creation-onlog-n&quot;&gt;Creation $O(n\log n)$&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; Use presorted $P$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create $T_1(v)$ binary search tree.&lt;/li&gt;
  &lt;li&gt;If $P$ has only one point then create leaf else split $P$ into two sets $P_{\rm left}$ and $P_{\rm right}$ using $x_{\rm mid}$ median point. Recursively create $v_{\rm left}$ and $v_{\rm right}$ from $P_{\rm left}$ and $P_{\rm right}$ respectively. Create a node with $x_{\rm mid}$ and $v_{\rm left}$ and $v_{\rm right}$ left and right children of this node. Make $T_1(v)$ the associated structure of $v$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;querying-olog-2n-k&quot;&gt;Querying $O(\log ^2n +k)$&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Find $v_{\rm split}$&lt;/li&gt;
  &lt;li&gt;If $v_{\rm split}$ is a leaf check point inside it and report if necessary.&lt;/li&gt;
  &lt;li&gt;Else
    &lt;ul&gt;
      &lt;li&gt;Follow path to $x$ and perform 1-D range query on the subtrees right of the path. Also check if point stored at the final leaf node $v$ must be reported.&lt;/li&gt;
      &lt;li&gt;Similary do for $x’$ and perform 1-D range query on the subtrees left of the path from $v_{\rm split}$. Again check at the end for the point stored at $v$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fractional-cascading&quot;&gt;Fractional Cascading&lt;/h2&gt;

&lt;p&gt;If two sets of objects $S_1$ and $S_2$ are stored int sorted arrays $A_1$ and $A_2$. To find keys in $[y:y’]$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We can binary search for ceil of  $y$ in $A_1$ and then walk along the array until the floor of $y’$. Similary for $S_2$. Total time will be $O(k)$ plus two binary searches ($k$ reported objects).&lt;/li&gt;
  &lt;li&gt;If $S_2\subseteq S_1$ we can maintain pointers from $A_1$ to $A_2$, i.e. we store the pointer to ceil key for every value in $A_1$. This will avoid the second binary search.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/rangetree2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure: Layered Range Tree showing only x-coordinates. Full points are given below&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Similarly $P(lc(v))\subseteq P(v)$ and $P(rc(v))\subseteq P(v)$. Instead of associated binary trees we will store an array sorted on the y-coordinates. Each value in the array will additionaly store two pointers to $A(lc(v))$ and $A(rc(v))$. This becomes the &lt;strong&gt;layered range tree&lt;/strong&gt;. This makes the query time $O(\log n + k)$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/rangetree3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure: The associated arrays with the nodes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While querying for $[x:x’]\times[y:y’]$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We search for $x$, $x’$ and $v_{\rm split}$. At $A(v_{\rm split})$ we we find the ceil entry of $y$.&lt;/li&gt;
  &lt;li&gt;While searching in $x$ and $x’$ in main tree we keep track of ceil entry of $y$ by following pointers in constant time.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 20 Oct 2019 15:54:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/data%20structures/range-trees.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/data%20structures/range-trees.html</guid>
        
        
        <category>Notes</category>
        
        <category>Data Structures</category>
        
      </item>
    
      <item>
        <title>Interval Trees</title>
        <description>&lt;h1 id=&quot;motivation&quot;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;Given a set of intervals $I$ on the real line and a query point $q_x$, find the intervals that contain $q_x$.&lt;/p&gt;

&lt;p&gt;Let $I:={[x_1:x_1’],[x_2:x_2’],\ldots,[x_n:x_n’]}$. Let $x_{\rm mid}$ be the median of the $2n$ interval endpoints such that atmost half of them lie on the left and half of them lie on the right.&lt;/p&gt;

&lt;h1 id=&quot;definition&quot;&gt;Definition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/intervaltree1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If $I=\phi$ then interval tree is a leaf.&lt;/li&gt;
  &lt;li&gt;Otherwise let $x_{\rm mid}$ be the median of the endpoints of the interval. Let
    &lt;ul&gt;
      &lt;li&gt;$I_{\rm left}:={[x_j:x_j’]\in I\mid x_j’&amp;lt;x_{\rm mid}}$&lt;/li&gt;
      &lt;li&gt;$I_{\rm mid}:={[x_j:x_j’]\in I\mid x_j\le x_{\rm mid}\le x_j’}$.&lt;/li&gt;
      &lt;li&gt;$I_{\rm right}:={[x_j:x_j’]\in I\mid x_j&amp;gt;x_{\rm mid}}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/intervaltree2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Interval tree consists of a root node $v$ storing $x_{\rm mid}$.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$I_{\rm mid}$ is stored twice:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;${\cal L}_{\rm left}$ that is sorted on the left endpoints of $I_{\rm mid}$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;${\cal L}_{\rm right}$ that is sorted on the right endpoints of  $I_{\rm mid}$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Left subtree of $v$ is an interval tree for the set $I_{\rm left}$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Right subtree of $v$ is an interval tree for the set $I_{\rm right}$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;creation-onlog-n&quot;&gt;Creation $O(n\log n)$&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;language-pseudocode&quot;&gt;create(I)
  if I = null
    return empty leaf
  else
    create a node v
    computer x_mid (linear time, constant if presorted)
    store x_mid with v
    compute I_mid, L_left, L_right
    left_child(v) &amp;lt;- create(I_left)
    right_child(v) &amp;lt;- create(I_right)
    return v
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;querying-olog-nk&quot;&gt;Querying $O(\log n+k)$&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;If $q_x &amp;lt; x_{\rm mid}(v)$ walk along $\cal L_{\rm left}$ reporting all intervals that contain $q_x$. Stop as soon as an interval doesn’t contain $q_x$. Query left subtree of $v$.&lt;/li&gt;
  &lt;li&gt;Symmetrically do for $q_x&amp;gt;x_{\rm mid(v)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$k$ = Number of reported intervals.&lt;/p&gt;

&lt;h1 id=&quot;2-d-range-tree&quot;&gt;2-D Range Tree&lt;/h1&gt;

&lt;p&gt;The data structure to store a a horizontal line segments is $\rm T$. If we want to create a 2-D range tree then instead of $\cal L_{\rm left}(v)$ and $\cal L_{\rm right}(v)$ we will store:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A range tree $T_{\rm left}(v)$ on left endpoint segments in $I_{\rm mid}(v)$.&lt;/li&gt;
  &lt;li&gt;A range tree $T_{\rm right}(v)$ on right endpoint segments in $I_{\rm mid}(v)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At time of querying instead of walking along $\cal L_{\rm left}(v)$ and $\cal L_{\rm right}(v)$ we will perform a query in the range trees $\rm T_{left}(v)$ and $\rm T_{right}(v)$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Creation: $O(n\log n)$&lt;/li&gt;
  &lt;li&gt;Querying: $O(\log^2n+k)$&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 20 Oct 2019 13:07:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/data%20structures/interval-trees.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/data%20structures/interval-trees.html</guid>
        
        
        <category>Notes</category>
        
        <category>Data Structures</category>
        
      </item>
    
      <item>
        <title>Red Black Trees</title>
        <description>&lt;h1 id=&quot;properties&quot;&gt;Properties&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Red/Black node&lt;/li&gt;
  &lt;li&gt;Root and leaf black&lt;/li&gt;
  &lt;li&gt;Children of red nodes are both black&lt;/li&gt;
  &lt;li&gt;All paths to leaves contains same nubmer of black nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Same as 2-3-4 tree (t=2) B-Tree.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Node with single value is same as a red node&lt;/li&gt;
  &lt;li&gt;Node with two values is same as a red node with a black child.&lt;/li&gt;
  &lt;li&gt;Node with three values is same as a red node with 2 black children.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 20 Oct 2019 12:59:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/data%20structures/notes/red-black-trees.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/data%20structures/notes/red-black-trees.html</guid>
        
        
        <category>Data Structures</category>
        
        <category>Notes</category>
        
      </item>
    
      <item>
        <title>B-Trees</title>
        <description>&lt;h1 id=&quot;definition&quot;&gt;Definition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/btree1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure: B-Tree of height 3 containing minimum number of keys&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Every node $x$ has $x.n$ keys and $x.n+1$ children (possibly undefined).&lt;/li&gt;
  &lt;li&gt;The key $x.k_i$ separates the range of keys stores in children subtrees, say $l_i$ then $l_1\le x.k_1\le l_2\le x.k_2\le \ldots x.k_n \le l_{n+1}$&lt;/li&gt;
  &lt;li&gt;All leaves have same depth&lt;/li&gt;
  &lt;li&gt;Each node except root has $t-1$ keys to $2t-1$ keys. Therefore $t$ to $2t$ children.&lt;/li&gt;
  &lt;li&gt;Height of tree $h=O(\log_tn)$&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;operations&quot;&gt;Operations&lt;/h1&gt;

&lt;h2 id=&quot;search-othotlog_tn&quot;&gt;Search $O(th)=O(t\log_tn)$&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Find the subtree where given key exists using linear search&lt;/li&gt;
  &lt;li&gt;recurse in that tree&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;create-o1&quot;&gt;Create $O(1)$&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Create a empty root node&lt;/li&gt;
  &lt;li&gt;Insert keys&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;insert-othotlog_tn&quot;&gt;Insert $O(th)=O(t\log_tn)$&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Find the the leaf node by searching.&lt;/li&gt;
  &lt;li&gt;If node is full split on median key to make two children nodes and insert the meadian key into parent node.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For single pass, split whenever you come across a full node while searching so as to be assured to no more split any nodes while shifting the median key upwards.&lt;/p&gt;

&lt;h2 id=&quot;splitting&quot;&gt;Splitting&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://adityagupta1089.github.io/images/btree2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure: Splitting a node with $t=4$&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Make two nodes with keys less than and more than the median key respectively.&lt;/li&gt;
  &lt;li&gt;Move the children between the keys to respective trees.&lt;/li&gt;
  &lt;li&gt;Move the median key to parent node.&lt;/li&gt;
  &lt;li&gt;Move the children around the median key to the left and right new nodes respectively.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;delete-othotlog_tn&quot;&gt;Delete $O(th)=O(t\log_tn)$&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;If key $k$ is in leaf node $x$ then delete $k$ from $x$.&lt;/li&gt;
  &lt;li&gt;If key $k$ is in internal node $x$ then
    &lt;ul&gt;
      &lt;li&gt;If left child $y$ of $k$ has $\ge t$ keys then find predecessor $k’$ of $k$ in $y$. Delete $k’$ from $y$ and replace $k$ by $k’$ in $x$.&lt;/li&gt;
      &lt;li&gt;Otherwise check for right child $z$ and do symmetrically.&lt;/li&gt;
      &lt;li&gt;Otherwise merge $y$ and $z$ along with $k$ into $y$. Recursively delete $k$ from $y$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 14 Oct 2019 09:33:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/data%20structures/b-trees.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/data%20structures/b-trees.html</guid>
        
        
        <category>Notes</category>
        
        <category>Data Structures</category>
        
      </item>
    
      <item>
        <title>Decision Trees</title>
        <description>&lt;h1 id=&quot;entropy-2-class&quot;&gt;Entropy 2-class&lt;/h1&gt;

&lt;p&gt;If $\cal I$ is the set of training examples, $p_+$ ratio of posititive examples in $\cal I$ and $p_-$ negative examples then entropy which measures impurity:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{Entropy}(I) = -p_+\log_2p_+ - p_-\log _2p_-&lt;/script&gt;

&lt;p&gt;This represents expected number of bits to encode the class of a randomly drawn member of $\cal I$&lt;/p&gt;

&lt;h1 id=&quot;information-gain&quot;&gt;Information Gain&lt;/h1&gt;

&lt;p&gt;Expected reduction in entropy due to sorting on attribute $x_i$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{Gain}({\cal I}, x_i)=\text{Entropy}(I)-\sum_{v\in\text{values}(x
_i)}\frac{|\cal I_v|}{|\cal I|}\text{Entropy}(\cal I_v)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$\text{values}(x_i)$: all possible values of $x_i$&lt;/li&gt;
  &lt;li&gt;$\cal I_v\subset \cal I$ : points in $\cal I$ that take value $v$ for $x_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;mutual-information-gain--information-gain&quot;&gt;Mutual Information Gain &amp;amp; Information Gain&lt;/h1&gt;

&lt;p&gt;Mutual information is the measure of mutual dependence of two random variables.&lt;/p&gt;

&lt;p&gt;Mutual information gain for two random variables $X$ and $Y$ is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(X;Y)=\sum_{y\in Y}\sum_{x\in X}p(x, y)\log\left(\frac{p(x,y)}{p(x)p(y)}\right)&lt;/script&gt;

&lt;p&gt;In decision trees mutual information gain and information gain are synonymous:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(X;Y)=H(Y)-H(Y|X)&lt;/script&gt;

&lt;h1 id=&quot;id3-algorithm&quot;&gt;ID3 Algorithm&lt;/h1&gt;

&lt;p&gt;Recursively perform on all examples.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For all $+$/$-$ examples return single node with corresponding label.&lt;/li&gt;
  &lt;li&gt;Otherwise split on attribute that best classifies current set of examples.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;decision-trees-features&quot;&gt;Decision Trees Features&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Hypothesis space is complete&lt;/li&gt;
  &lt;li&gt;Only single hypothesis as output&lt;/li&gt;
  &lt;li&gt;No backtracking&lt;/li&gt;
  &lt;li&gt;Statistically based choices&lt;/li&gt;
  &lt;li&gt;True bias hard to estimate&lt;/li&gt;
  &lt;li&gt;Shorter trees are preferred&lt;/li&gt;
  &lt;li&gt;Trees with high information gain near root are preferred&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;overfitting&quot;&gt;Overfitting&lt;/h1&gt;

&lt;p&gt;Hypothesis $h\in \cal H$ overfits $X$ if $\exists h’$ such that:&lt;/p&gt;

&lt;p&gt;$E(h|X)&amp;lt; E(h’|X)$ but $E_p(h)&amp;gt;E_p(h’)$ where $p$ is the entire distribution of data.&lt;/p&gt;

&lt;p&gt;Strategies:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stop when insignificant information gain&lt;/li&gt;
  &lt;li&gt;post pruning  - subtrees/rules/&lt;/li&gt;
  &lt;li&gt;using ensembles&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;problems&quot;&gt;Problems&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Real values functions - sort and split on midpoints&lt;/li&gt;
  &lt;li&gt;Alternative measures for selecting attributes - gain ratio / cost sensitive information gain&lt;/li&gt;
  &lt;li&gt;Missing attribute values - most commomn value at node / node with same target value / probability based on descendents of node&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;advantages--disadvantages&quot;&gt;Advantages / Disadvantages&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Easy to explain&lt;/li&gt;
  &lt;li&gt;No hyperparameters&lt;/li&gt;
  &lt;li&gt;Overfitting&lt;/li&gt;
  &lt;li&gt;Low accuracies (cf. other approaches)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;random-forests&quot;&gt;Random Forests&lt;/h1&gt;

&lt;h2 id=&quot;instane-bagging--bootstrap-aggregation&quot;&gt;Instane Bagging / Bootstrap aggregation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Generate $K$ different bootstrapped trainig datasets (sampling with replacement)&lt;/li&gt;
  &lt;li&gt;Learn a decision tree on each&lt;/li&gt;
  &lt;li&gt;Final prediction is the majority/average vote of all.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;freature-bagging&quot;&gt;Freature bagging&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Improved than instance bagging&lt;/li&gt;
  &lt;li&gt;Build a decision tree using a subset of $m$ features rather than all $D$ features, typically $m\approx \sqrt D$&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 14 Oct 2019 09:29:00 +0000</pubDate>
        <link>https://adityagupta1089.github.io/notes/machine%20learning/decision-trees.html</link>
        <guid isPermaLink="true">https://adityagupta1089.github.io/notes/machine%20learning/decision-trees.html</guid>
        
        
        <category>Notes</category>
        
        <category>Machine Learning</category>
        
      </item>
    
  </channel>
</rss>
